{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from typing import List\n",
    "import graphviz\n",
    "from pathlib import Path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our embedding class (same as before)\n",
    "class SimpleHashEmbeddings(Embeddings):\n",
    "    def __init__(self, dimension: int = 384):\n",
    "        self.dimension = dimension\n",
    "    \n",
    "    def _hash_text(self, text: str) -> List[float]:\n",
    "        hash_object = hashlib.sha256(text.encode())\n",
    "        hash_hex = hash_object.hexdigest()\n",
    "        float_array = []\n",
    "        for i in range(0, len(hash_hex), 8):\n",
    "            chunk = hash_hex[i:i+8]\n",
    "            float_val = int(chunk, 16) / 2**32 - 1\n",
    "            float_array.append(float_val)\n",
    "        array = np.array(float_array, dtype=np.float32)\n",
    "        if len(array) < self.dimension:\n",
    "            array = np.pad(array, (0, self.dimension - len(array)))\n",
    "        else:\n",
    "            array = array[:self.dimension]\n",
    "        norm = np.linalg.norm(array)\n",
    "        if norm > 0:\n",
    "            array = array / norm\n",
    "        return array.tolist()\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._hash_text(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._hash_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our documentation prompts\n",
    "documentation_prompts = {\n",
    "    'overview': PromptTemplate(\n",
    "        input_variables=[\"code\"],\n",
    "        template=\"\"\"Analyze the following PL/SQL chess engine code and provide a comprehensive overview:\n",
    "\n",
    "{code}\n",
    "\n",
    "Please provide:\n",
    "1. High-level overview of the system\n",
    "2. Main components and their purposes\n",
    "3. Key functionalities\n",
    "4. Design patterns used\n",
    "5. Important dependencies\n",
    "\"\"\"\n",
    "    ),\n",
    "    \n",
    "    'architecture': PromptTemplate(\n",
    "        input_variables=[\"code\"],\n",
    "        template=\"\"\"Analyze the following PL/SQL chess engine code and describe its architecture:\n",
    "\n",
    "{code}\n",
    "\n",
    "Please provide:\n",
    "1. System architecture overview\n",
    "2. Component interactions\n",
    "3. Data flow description\n",
    "4. Key interfaces\n",
    "5. Architectural patterns used\n",
    "\n",
    "Also provide a mermaid diagram showing the architecture.\n",
    "\"\"\"\n",
    "    ),\n",
    "    \n",
    "    'procedure_analysis': PromptTemplate(\n",
    "        input_variables=[\"code\", \"procedure_name\"],\n",
    "        template=\"\"\"Analyze the following PL/SQL procedure/function in detail:\n",
    "\n",
    "Procedure/Function: {procedure_name}\n",
    "\n",
    "Code:\n",
    "{code}\n",
    "\n",
    "Please provide:\n",
    "1. Purpose and functionality\n",
    "2. Input parameters and their usage\n",
    "3. Return values and their meaning\n",
    "4. Algorithm explanation\n",
    "5. Error handling approach\n",
    "6. Performance considerations\n",
    "7. Dependencies and side effects\n",
    "\"\"\"\n",
    "    ),\n",
    "    \n",
    "    'migration_analysis': PromptTemplate(\n",
    "        input_variables=[\"code\"],\n",
    "        template=\"\"\"Analyze the following PL/SQL code and provide a detailed migration approach:\n",
    "\n",
    "{code}\n",
    "\n",
    "Please provide:\n",
    "1. Recommended target technology stack\n",
    "2. Step-by-step migration plan\n",
    "3. Potential challenges and solutions\n",
    "4. Required code transformations\n",
    "5. Testing strategy\n",
    "6. Estimated effort and complexity\n",
    "\"\"\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vector store and metadata\n",
    "print(\"Loading vector store and metadata...\")\n",
    "embeddings = SimpleHashEmbeddings(dimension=384)\n",
    "vectorstore = FAISS.load_local(\"vectorstore\", embeddings)\n",
    "\n",
    "with open(\"chess_metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(\n",
    "    model=\"llama2:latest\",\n",
    "    temperature=0.2,\n",
    "    verbose=True,\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# Create documentation chains\n",
    "doc_chains = {name: LLMChain(llm=llm, prompt=prompt) \n",
    "             for name, prompt in documentation_prompts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_documentation():\n",
    "    \"\"\"Generate comprehensive documentation for the chess engine\"\"\"\n",
    "    documentation = {\n",
    "        'generated_at': datetime.datetime.now().isoformat(),\n",
    "        'overview': {},\n",
    "        'architecture': {},\n",
    "        'packages': {},\n",
    "        'migration_analysis': {}\n",
    "    }\n",
    "    \n",
    "    print(\"Generating system overview...\")\n",
    "    # Get overall system context\n",
    "    system_docs = vectorstore.similarity_search(\n",
    "        \"chess engine system overview architecture main components\", k=5)\n",
    "    combined_system_text = \"\\n\\n\".join([doc.page_content for doc in system_docs])\n",
    "    \n",
    "    # Generate overview\n",
    "    documentation['overview'] = doc_chains['overview'].run(code=combined_system_text)\n",
    "    \n",
    "    # Generate architecture documentation\n",
    "    documentation['architecture'] = doc_chains['architecture'].run(code=combined_system_text)\n",
    "    \n",
    "    print(\"\\nAnalyzing individual packages...\")\n",
    "    # Process each package\n",
    "    for package in metadata['packages']:\n",
    "        package_name = package['package_name']\n",
    "        print(f\"Processing package: {package_name}\")\n",
    "        \n",
    "        package_docs = vectorstore.similarity_search(\n",
    "            f\"package {package_name} implementation details\", k=3)\n",
    "        package_text = \"\\n\\n\".join([doc.page_content for doc in package_docs])\n",
    "        \n",
    "        package_info = {\n",
    "            'overview': doc_chains['overview'].run(code=package_text),\n",
    "            'procedures': {}\n",
    "        }\n",
    "        \n",
    "        # Process each procedure in the package\n",
    "        for routine in package['routines']:\n",
    "            routine_name = routine['name']\n",
    "            print(f\"  Analyzing procedure: {routine_name}\")\n",
    "            \n",
    "            routine_docs = vectorstore.similarity_search(\n",
    "                f\"package {package_name} procedure {routine_name} implementation\", k=2)\n",
    "            routine_text = \"\\n\\n\".join([doc.page_content for doc in routine_docs])\n",
    "            \n",
    "            package_info['procedures'][routine_name] = \\\n",
    "                doc_chains['procedure_analysis'].run(\n",
    "                    code=routine_text,\n",
    "                    procedure_name=routine_name\n",
    "                )\n",
    "        \n",
    "        documentation['packages'][package_name] = package_info\n",
    "    \n",
    "    print(\"\\nGenerating migration analysis...\")\n",
    "    # Generate migration analysis\n",
    "    documentation['migration_analysis'] = doc_chains['migration_analysis'].run(\n",
    "        code=combined_system_text)\n",
    "    \n",
    "    # Save documentation\n",
    "    output_file = f\"chess_engine_documentation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(documentation, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDocumentation generated and saved to {output_file}\")\n",
    "    return documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown documentation\n",
    "def generate_markdown_documentation(documentation):\n",
    "    \"\"\"Convert the JSON documentation to markdown format\"\"\"\n",
    "    md_content = []\n",
    "    \n",
    "    # Title\n",
    "    md_content.append(\"# Chess Engine Documentation\")\n",
    "    md_content.append(f\"Generated on: {documentation['generated_at']}\\n\")\n",
    "    \n",
    "    # System Overview\n",
    "    md_content.append(\"## System Overview\")\n",
    "    md_content.append(documentation['overview'])\n",
    "    \n",
    "    # Architecture\n",
    "    md_content.append(\"\\n## System Architecture\")\n",
    "    md_content.append(documentation['architecture'])\n",
    "    \n",
    "    # Packages\n",
    "    md_content.append(\"\\n## Packages\")\n",
    "    for package_name, package_info in documentation['packages'].items():\n",
    "        md_content.append(f\"\\n### Package: {package_name}\")\n",
    "        md_content.append(\"#### Overview\")\n",
    "        md_content.append(package_info['overview'])\n",
    "        \n",
    "        md_content.append(\"\\n#### Procedures and Functions\")\n",
    "        for proc_name, proc_doc in package_info['procedures'].items():\n",
    "            md_content.append(f\"\\n##### {proc_name}\")\n",
    "            md_content.append(proc_doc)\n",
    "    \n",
    "    # Migration Analysis\n",
    "    md_content.append(\"\\n## Migration Analysis\")\n",
    "    md_content.append(documentation['migration_analysis'])\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = f\"chess_engine_documentation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(md_content))\n",
    "    \n",
    "    print(f\"Markdown documentation saved to {output_file}\")\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete documentation\n",
    "documentation = generate_full_documentation()\n",
    "\n",
    "# Convert to markdown\n",
    "markdown_file = generate_markdown_documentation(documentation)\n",
    "\n",
    "print(\"\\nDocumentation generation complete!\")\n",
    "print(f\"JSON documentation and Markdown files have been generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
